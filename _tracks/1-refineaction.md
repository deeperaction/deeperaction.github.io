---
title: "RefineAction Challenge on Temporal Action Localization"
excerpt: "Detecting all segments of containing actions of interest and recognizing their categories from a long video sequence. <br/><img src='/images/refinedaction.gif'>"
collection: tracks
---

<img src='/images/refinedaction_ori.gif' width="500" height="300">
{:.text-center}

**Track Organizers**: Yi Liu [yi.liu1@siat.ac.cn](mailto:yi.liu1@siat.ac.cn), Xiao Ma [xiao.ma@sait.ac.cn](mailto:xiao.ma@sait.ac.cn)

Most existing action localization datasets are built upon coarse action categories, e.g., “Layup drill in basketball” in ActivityNet rather than “dunk basketball” or “cast basketball”. As such coarse categories are often highly related with background context, their temporal annotations often lack clear boundaries to describe detailed actions. 
{:.text-justify}

To fill this gap, we propose a new benchmark, RefineAction, which is a large and more-refined video dataset for temporal action localization. Different from the previous datasets, our RefineAction contains two distinguished features.
{:.text-justify}
1. The definition of action categories is much more refined, and an action can be divided into more subtle atomic actions.
2. The annotation rules and procedures are more accurate with cross-check, reducing the boundary uncertainty for temporal action localization. 
{:.text-justify}

We expect that such refined dataset can bring new challenges and novel contributions in the research of temporal action localization. 
{:.text-justify}